{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WiYYTYCXuFzm"
   },
   "source": [
    "# Crawling Part\n",
    "In this project we will predict if the costumer review on the resturant will be good or bad. We will learn about different parameters of comments by analize the word in it.\n",
    "In this section we will deal with Crawling.\n",
    "\n",
    "Our data aquision is devided to 2 parts - resturants and comments. Our data will be collected from <https://easy.co.il>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVQ3e-u8vX1Y"
   },
   "source": [
    "## Importing Libraries\n",
    "the next block will be responsible for installing and importing the necessary libraries and functions for this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t79exoNrwBz7"
   },
   "source": [
    "download necesery packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Svi9hQIvv0Fx"
   },
   "outputs": [],
   "source": [
    "#pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axNKNPmrsLJW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Dqy5hGiwQDp"
   },
   "source": [
    "#### Setup Selenium initial definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "pqhabDj0vpDl",
    "outputId": "f8ddcd95-f54a-4beb-f47b-b2827950e390",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "base_url = \"https://easy.co.il/list/Restaurants-and-Fast-Food\"\n",
    "driver.get(base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3wTvyp7xBpH"
   },
   "source": [
    "### Initial 2 DataFrames\n",
    "**1) Resturants DF**- will contain data on each resturant\n",
    "\n",
    "**2) Comments DF** - will contain the comments we found in each resturant comments review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resturants_df = pd.DataFrame()\n",
    "comments_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section we will get the data for the resturant df with Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resturant_name():\n",
    "    name = \"\"\n",
    "    try:\n",
    "        name = driver.find_element(by=By.CLASS_NAME, value= 'biz-title')\n",
    "        if('\\n' in name.text):\n",
    "            name = name.text[0 : name.text.index('\\n')]\n",
    "        else:\n",
    "            name = name.text\n",
    "    except:\n",
    "        name = None\n",
    "    return name\n",
    "\n",
    "def get_resturant_phone():\n",
    "    phone = \"\"\n",
    "    try:\n",
    "        phone = driver.find_element(by=By.ID, value= 'action-phone-label').text\n",
    "    except:\n",
    "        phone=None\n",
    "    return phone\n",
    "\n",
    "def get_resturant_address():\n",
    "    address = \"\"\n",
    "    try:\n",
    "        address = driver.find_element(by=By.CLASS_NAME, value= 'biz-address-text').text\n",
    "    except:\n",
    "        address=None\n",
    "    return address\n",
    "\n",
    "def get_opening_hours():\n",
    "    hours = \"\"\n",
    "    try:\n",
    "        button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, 'open-hours')))\n",
    "        button.click()\n",
    "        hours = driver.find_element(by=By.CLASS_NAME, value=\"open-hours-content\").text\n",
    "        button.click()\n",
    "    except:\n",
    "        hours = None\n",
    "    return hours\n",
    "\n",
    "def get_resturant_type():\n",
    "    resturant_type = \"\"\n",
    "    try:\n",
    "        resturant_type = driver.find_element(by=By.CLASS_NAME, value= 'best-sub-cat').text\n",
    "    except:\n",
    "        resturant_type = None\n",
    "    return resturant_type\n",
    "\n",
    "def get_resturant_rating():\n",
    "    rating = 0\n",
    "    try:\n",
    "        rating = driver.find_elements(by=By.CLASS_NAME, value= 'easy-score')[1].text\n",
    "    except:\n",
    "        rating = -1\n",
    "    return rating\n",
    "\n",
    "def get_is_resturant_has_deliveries():\n",
    "    try:\n",
    "        return \"משולחים\" in driver.find_element(by=By.CLASS_NAME, value= 'upper-buttons-scroll-box').text\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def get_is_resturant_has_table_reservation():\n",
    "    try:\n",
    "        return \"הזמנת שולחן\" in driver.find_element(by=By.CLASS_NAME, value= 'upper-buttons-scroll-box').text\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def get_is_resturant_has_menu():\n",
    "    try:\n",
    "        return \"תפריט\" in driver.find_element(by=By.CLASS_NAME, value= 'upper-buttons-scroll-box').text\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def get_is_resturant_has_sending_a_massage():\n",
    "    try:\n",
    "        return \"הודעה\" in driver.find_element(by=By.CLASS_NAME, value= 'upper-buttons-scroll-box').text\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def get_element_item_from_list(list, text_to_search):\n",
    "    for index, item in enumerate(list):\n",
    "        if(text_to_search in item.text):\n",
    "            return item\n",
    "\n",
    "def get_url(what_to_get):\n",
    "    link = \"\"\n",
    "    try:\n",
    "        lst = driver.find_elements(by=By.CLASS_NAME, value= 'biz-action-button')\n",
    "        face=get_element_item_from_list(lst,what_to_get).get_attribute('innerHTML')\n",
    "        position = -1\n",
    "        for i in range(0, 2):\n",
    "            position = face.find('\"', position + 1)\n",
    "\n",
    "        link = face[face.index('\"') + 1 : position]\n",
    "    except:\n",
    "        link = None\n",
    "    return link\n",
    "\n",
    "def get_resturant_positive_reviews_count():\n",
    "    positive_reviews_count = 0\n",
    "    try:\n",
    "        positive_reviews = driver.find_element(by=By.CLASS_NAME, value='green')\n",
    "        positive_reviews_count = positive_reviews.text[ positive_reviews.text.index('(') + 1 : positive_reviews.text.index(')') ]\n",
    "    except:\n",
    "        positive_reviews_count = -1\n",
    "    return positive_reviews_count\n",
    "\n",
    "def get_resturant_negative_reviews_count():\n",
    "    negative_reviews_count = 0\n",
    "    try:\n",
    "        negative_reviews = driver.find_element(by=By.CLASS_NAME, value='red')\n",
    "        negative_reviews_count = negative_reviews.text[ negative_reviews.text.index('(') + 1 : negative_reviews.text.index(')') ]\n",
    "    except:\n",
    "        negative_reviews_count = -1\n",
    "    return negative_reviews_count\n",
    "\n",
    "def get_resturant_expert_reviews_count():\n",
    "    expert_reviews_count = 0\n",
    "    try:\n",
    "        expert_reviews = driver.find_element(by=By.CLASS_NAME, value='yellow')\n",
    "        expert_reviews_count = expert_reviews.text[ expert_reviews.text.index('(') + 1 : expert_reviews.text.index(')') ]\n",
    "    except:\n",
    "        expert_reviews_count = -1\n",
    "    return expert_reviews_count\n",
    "\n",
    "def get_resturant_side_data(what_to_search):\n",
    "    result = 0\n",
    "    try:\n",
    "        parentElement = driver.find_element(by=By.CLASS_NAME, value=\"biz-card-items\")\n",
    "        elementsList = parentElement.find_elements(by=By.CLASS_NAME, value=\"card-text\")\n",
    "        for index,item in enumerate(elementsList):\n",
    "            text=item.get_attribute('innerText')\n",
    "            count=text[0 : text.index('\\n')]\n",
    "            what = text[text.index('\\n')+1:].strip()\n",
    "            if(what_to_search in what):\n",
    "                result = count\n",
    "    except:\n",
    "        result = -1\n",
    "    return result\n",
    "\n",
    "def get_is_resturant_has_discounts_and_benefits():\n",
    "    try:\n",
    "        driver.find_element(by=By.CLASS_NAME, value=\"biz-benefits\")\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def get_resturant_postal_code():\n",
    "    postal_code=0\n",
    "    try:\n",
    "        elementsList = driver.find_elements(by=By.CLASS_NAME, value=\"info-item\")\n",
    "        for index,item in enumerate(elementsList):\n",
    "            if('מיקוד' in item.text):\n",
    "                postal_code=item.text[item.text.index(' ') + 1 : ]\n",
    "    except:\n",
    "        postal_code = -1\n",
    "    return postal_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section we will get the data for the comments df with Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_customer_name(item):\n",
    "    customer_name= \"\"\n",
    "    try:\n",
    "        customer_name = item.find_element(by=By.CLASS_NAME, value= 'review-name').text\n",
    "    except:\n",
    "        customer_name= None\n",
    "    return customer_name\n",
    "\n",
    "def get_customer_reviews_number(item):\n",
    "    customer_reviews_number = \"\"\n",
    "    try:\n",
    "        customer_reviews_number = item.find_element(by=By.CLASS_NAME, value= 'easy-reviews-count')\n",
    "        customer_reviews_number= customer_reviews_number.text[0:customer_reviews_number.text.index(' ')]\n",
    "    except:\n",
    "        customer_reviews_number = None\n",
    "    return customer_reviews_number\n",
    "\n",
    "def get_customer_reviews_date(item):\n",
    "    customer_reviews_date = \"\"\n",
    "    try:\n",
    "        customer_reviews_date = item.find_element(by=By.CLASS_NAME, value= 'review-date').text\n",
    "    except:\n",
    "        customer_reviews_date = None\n",
    "    return customer_reviews_date\n",
    "\n",
    "def get_comment(item):\n",
    "    comment=\"\"\n",
    "    try:\n",
    "        comment = item.find_element(by=By.CLASS_NAME, value= 'review-text').find_element(by=By.CSS_SELECTOR, value= 'p').text\n",
    "    except:\n",
    "        comment= None\n",
    "    return comment\n",
    "\n",
    "def get_number_of_star(item):\n",
    "    number_of_star=\"\"\n",
    "    try:\n",
    "        parentImg = item.find_element(by=By.CLASS_NAME, value=\"review-right\")\n",
    "        img = parentImg.find_element(by=By.CLASS_NAME, value='review-icon')\n",
    "        src = img.get_attribute('src')\n",
    "        number_of_star = src[46] \n",
    "    except:\n",
    "        number_of_star= None\n",
    "    return number_of_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comments of each resturant place in multiple pages.\n",
    "\n",
    "In this Section we are calling the crawling function for *comments* and navigate to the next page after finishing the current page.\n",
    "\n",
    "We saw that on each page there are 15 comments and we get the amount of comments for the resturant, we calculate how mush pages are avaliable for the resturant and navigate accordingly (for loop)\n",
    "\n",
    "**Output**: all the comments of the resturant in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_comments(base_url):\n",
    "    resturant_name=[]\n",
    "    customer_name=[]\n",
    "    customer_reviews_number=[]\n",
    "    customer_reviews_date=[]\n",
    "    comments=[]\n",
    "    number_number_of_star=[]\n",
    "    total_reviews = 0\n",
    "    active_revies = driver.find_element(by=By.CLASS_NAME, value=\"reviews-tabs\").find_element(by=By.CLASS_NAME, value=\"active\")\n",
    "    if(\"ביקורות\" in active_revies.text):\n",
    "        total_reviews = int(active_revies.text[active_revies.text.index('(')+1 : active_revies.text.index(')')])\n",
    "    total_pages = math.ceil(total_reviews/15)\n",
    "    for page_number in range(1, total_pages + 1):\n",
    "        try:\n",
    "            driver.get(base_url + \"?reviewpage=\" + str(page_number))\n",
    "            parentElement = driver.find_element(by=By.CLASS_NAME, value=\"reviews-items\")\n",
    "            elementsList = parentElement.find_elements(by=By.CLASS_NAME, value=\"easy-review\")\n",
    "            for index,item in enumerate(elementsList):\n",
    "                resturant_name.append(get_resturant_name())\n",
    "                customer_name.append(get_customer_name(item))\n",
    "                customer_reviews_number.append(get_customer_reviews_number(item))\n",
    "                customer_reviews_date.append(get_customer_reviews_date(item))\n",
    "                comments.append(get_comment(item))\n",
    "                number_number_of_star.append(get_number_of_star(item))\n",
    "            sleep_time = random.randint(1, 10)\n",
    "            time.sleep(sleep_time)\n",
    "        except Exception as e:\n",
    "            print('no success',e)\n",
    "    df=pd.DataFrame({\"resturant_name\":resturant_name,\"customer_name\":customer_name,\"customer_reviews_number\":customer_reviews_number,\"customer_reviews_date\":customer_reviews_date,\"comments\":comments,\"number_number_of_star\":number_number_of_star})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Section we are calling the crawling function for *resturant* **without comments**.\n",
    "\n",
    "**Output**: resturant data object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resturant_data():\n",
    "    return {'Name': get_resturant_name(),\n",
    "            'Phone': get_resturant_phone(),\n",
    "            'Address': get_resturant_address(),\n",
    "            'Opening Hours': get_opening_hours(),\n",
    "            'Type': get_resturant_type(),\n",
    "            'Rating': get_resturant_rating(),\n",
    "            'Has Deliveries': get_is_resturant_has_deliveries(),\n",
    "            'Has Table Reservation': get_is_resturant_has_table_reservation(),\n",
    "            'Has Menu': get_is_resturant_has_menu(),\n",
    "            'Has Sending A Massage': get_is_resturant_has_sending_a_massage(),\n",
    "            'Facebook Url': get_url(\"פייסבוק\"),\n",
    "            'Instagram Url': get_url(\"אינסטגרם\"),\n",
    "            'Home Page Url': get_url(\"אתר הבית\"),\n",
    "            'Positive Reviews Count': get_resturant_positive_reviews_count(),\n",
    "            'Negative Reviews Count': get_resturant_negative_reviews_count(),\n",
    "            'Expert Reviews Count': get_resturant_expert_reviews_count(),\n",
    "            'Number Of Visits In Last Month': get_resturant_side_data(\"ביקרו פה החודש\"),\n",
    "            'Number Of Reviews': get_resturant_side_data(\"ביקורות\"),\n",
    "            'Number Of Top 3': get_resturant_side_data(\"TOP 3\"),\n",
    "            'Has Discounts And Benefits': get_is_resturant_has_discounts_and_benefits(),\n",
    "            'Postal Code': get_resturant_postal_code()}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are opening the website and search for location, we want to see all the resturants around.\n",
    "\n",
    "We need to scrool down the scroller to get the resturants.\n",
    "\n",
    "The next section will scroll down the page until no more resturants found around the selected location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_location(new_location):\n",
    "    WebDriverWait(driver, 1).until(EC.element_to_be_clickable((By.CLASS_NAME, 'change-location'))).click()\n",
    "    driver.find_element(by=By.ID, value=\"searchAddress\").send_keys(new_location)\n",
    "    WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.ID, 'biz-0'))).click()\n",
    "\n",
    "def scroll_page():\n",
    "    but = driver.find_element(by=By.ID, value=\"nextPageButton\")\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView(true);\", but)    \n",
    "    \n",
    "def show_all_resturants():\n",
    "    is_continue = True\n",
    "    count = 1\n",
    "    while is_continue:\n",
    "        try:\n",
    "            scroll_page()\n",
    "            WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.ID, \"nextPageButton\")))\n",
    "            button = WebDriverWait(driver, 10, 10).until(EC.element_to_be_clickable((By.ID, 'nextPageButton')))\n",
    "            button.click()\n",
    "            count = count + 1\n",
    "        except:\n",
    "            is_continue = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encountered difficulties during the crawling, were blocked dozens of times so we kept the restaurant links aside and ran the operation on a small portion of files each time\n",
    "\n",
    "The next sections will present the link save for \"תל אביב\" area and \"ראשון לציון\" area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_urls(file_name):\n",
    "    all_resturants=[]\n",
    "    current_resturant = \"\"\n",
    "    count = 1\n",
    "    try:\n",
    "        elementsList = driver.find_elements(by=By.CLASS_NAME, value=\"biz-item\")\n",
    "        for index,item in enumerate(elementsList):\n",
    "            resturant_url=item.find_element(by=By.CLASS_NAME, value=\"biz-item-link-wrapper\").get_attribute('href')\n",
    "            if(\"=\" in resturant_url):\n",
    "                resturnat_number = resturant_url[resturant_url.index(\"=\") + 1 : resturant_url.index(\"&\")]\n",
    "                all_resturants.append(\"https://easy.co.il/page/\" + resturnat_number)\n",
    "            else:\n",
    "                all_resturants.append(resturant_url)\n",
    "\n",
    "        df=pd.DataFrame({\"resturant_url\":all_resturants})\n",
    "        df.to_csv(file_name)\n",
    "\n",
    "       \n",
    "    except Exception as e:\n",
    "        print('error', current_resturant)\n",
    "        print(e)\n",
    "        print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_location(\"תל אביב\")\n",
    "# show_all_resturants()\n",
    "# save_all_urls(\"tel_aviv_urls.csv\")\n",
    "# change_location(\"ראשון לציון\")\n",
    "# show_all_resturants(\"rishon_letzion_urls.csv\")\n",
    "# save_all_urls()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section is the **main** section of our crawling.\n",
    "\n",
    "As we say earlier the resturants_url is taken from file we saved before in `save_all_urls()` func\n",
    "\n",
    "Foreach resturant in the file we create df with the data and add it to the current df.\n",
    "\n",
    "After we finish the crawling on each block of resturants we save it to the local storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_resturants=pd.read_csv(\"rishon_letzion_urls.csv\")\n",
    "# all_resturants=pd.read_csv(\"tel_aviv_urls.csv\")\n",
    "current_resturant = \"\"\n",
    "count = 1\n",
    "try:\n",
    "    for rest in all_resturants[\"resturant_url\"][count:count+20]:\n",
    "        current_resturant = rest\n",
    "        driver.get(rest)\n",
    "        resturants_df = resturants_df.append(get_resturant_data(), ignore_index=True)\n",
    "        comments_df = pd.concat([comments_df, get_all_comments(rest)])\n",
    "        sleep_time = random.randint(10, 30)\n",
    "        time.sleep(sleep_time)\n",
    "        count = count + 1\n",
    "except Exception as e:\n",
    "    print('error', current_resturant)\n",
    "    print(e)\n",
    "    print('---------')\n",
    "\n",
    "driver.close()\n",
    "resturants_df.to_csv('resturants1.csv', encoding = 'utf-8-sig')\n",
    "comments_df.to_csv('comments1.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Data Science Project - Crawling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
